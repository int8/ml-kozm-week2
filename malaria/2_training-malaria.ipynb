{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b4d77e-7938-4599-b2cc-5a6d4584e8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm \n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "def create_bbox_coords(bbox):\n",
    "    xmin = float(bbox.find('xmin').text)\n",
    "    ymin = float(bbox.find('ymin').text)\n",
    "    xmax = float(bbox.find('xmax').text)\n",
    "    ymax = float(bbox.find('ymax').text)\n",
    "    return [xmin, ymin, xmax, ymax]\n",
    "\n",
    "def create_mask(plasmodium_img, bbox):\n",
    "    xmin, ymin, xmax, ymax = create_bbox_coords(bbox)\n",
    "    mask = np.zeros((plasmodium_img.size[1], plasmodium_img.size[0]), dtype=np.uint8)\n",
    "    mask[int(ymin):int(ymax), int(xmin):int(xmax)] = 1 \n",
    "    return mask \n",
    "\n",
    "    \n",
    "class MalariaPlasmodiumDataset(torch.utils.data.Dataset):\n",
    "    # Będziemy czytać pliki jpg i odpowiadające im pliki XML \n",
    "    # z katalogu directory_root \n",
    "    # Podamy też transformacje jakie chcemy przeprowadzać na zwracanych wartościach \n",
    "    \n",
    "    def __init__(self, directory_root, images_transforms=None):\n",
    "\n",
    "        # Przypisujemy parametetry konstruktora do self \n",
    "        # Chcemy aby nasz przyszły obiekt wiedzial o tym gdzie szukać plików oraz \n",
    "        # jakie transformacje wykonywać na przeczytanych JPG \n",
    "        self.directory_root = directory_root        \n",
    "        self.images_transforms = images_transforms\n",
    "\n",
    "        # Listujemy wszystkie pliki które mają rozszerzenie \"JPG\" \n",
    "        all_image_files = sorted([img for img in os.listdir(directory_root) if img.endswith(\".jpg\")])\n",
    "        \n",
    "\n",
    "        # wśród zdjęć w naszym datasecie są takie, na których nie znaleziono zarodźca \n",
    "        # usuwamy je z datasetu - tzn zapisujemy do self.imgs_with_plasmodium tylko \n",
    "        self.imgs_with_plasmodium = []\n",
    "        for img_file in all_image_files:\n",
    "            xml_file = os.path.join(self.directory_root, img_file.replace(\".jpg\", \".xml\"))\n",
    "            tree = ET.parse(xml_file)\n",
    "            # wykrycie zarodźca na zdjęciu jpg jest równoważne z istnieniem taga \"object\" w XML - jeśli tylko znajdziemy takowy \n",
    "            # kwalifikujemy zdjęcie jako dobre do naszego wejściowego datasetu i dodajemy nazwę pliku do self.imgs_with_plasmodium  \n",
    "            if tree.findall('object'): \n",
    "                self.imgs_with_plasmodium.append(img_file)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        # \"magiczna\" metoda __getitem__ jest wykorzystywana kiedy chcemy aby nasz obiekt był dostępny poprzez operator [int] \n",
    "        # podobnie jak lista czy dict \n",
    "        single_plasmodium_img_path = self.get_single_plasmodium_path(idx)\n",
    "        single_annotation_file_path = single_plasmodium_img_path.replace(\".jpg\", \".xml\")\n",
    "        plasmodium_img = Image.open(single_plasmodium_img_path).convert(\"RGB\") \n",
    "        \n",
    "        # czytamy xml file\n",
    "        annotations = ET.parse(single_annotation_file_path)\n",
    "        boxes = []\n",
    "        masks = []        \n",
    "        \n",
    "        for detected_plasmodium in annotations.findall('object'):            \n",
    "            bbox = detected_plasmodium.find('bndbox')\n",
    "            # dodajemy bboxes\n",
    "            boxes.append(\n",
    "                create_bbox_coords(bbox)\n",
    "            )\n",
    "            # dodajemy maski \n",
    "            masks.append(\n",
    "                create_mask(\n",
    "                    plasmodium_img, bbox\n",
    "                )\n",
    "            )\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        masks = torch.as_tensor(np.array(masks), dtype=torch.uint8)  \n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        labels = torch.ones((len(boxes),), dtype=torch.int64)                                   \n",
    "        \n",
    "        if self.images_transforms is not None:\n",
    "            transformed_plasmodium_img = self.images_transforms(plasmodium_img)\n",
    "        else:\n",
    "            transformed_plasmodium_img = plasmodium_img            \n",
    "        # zapisujemy target dla jednego pliku img \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"masks\"] = masks\n",
    "        \n",
    "        return transformed_plasmodium_img, target\n",
    "\n",
    "    def get_single_plasmodium_path(self, idx):\n",
    "        single_plasmodium_img_path = os.path.join(self.directory_root, self.imgs_with_plasmodium[idx])\n",
    "        return single_plasmodium_img_path\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        # magiczna metoda __len__ jest używana gdy na instancji wykonujemy len() \n",
    "        return len(self.imgs_with_plasmodium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009151ea-5df0-4417-9dd3-405f8cfac13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def draw_bounding_boxes(image_path, bboxes, scores=None, color=(255, 0, 0), return_pt = False):    \n",
    "    img_pil = Image.open(image_path).convert(\"RGBA\")\n",
    "    new = Image.new('RGBA', img_pil.size, (255, 255, 255, 0))\n",
    "    draw = ImageDraw.Draw(new)\n",
    "\n",
    "    for i, box in enumerate(bboxes):\n",
    "        xmin, ymin, xmax, ymax = box        \n",
    "        if scores is not None:          \n",
    "            alpha = int(255 * scores[i])  # Convert score to an alpha value.                      \n",
    "            color_with_alpha = color + (alpha,)\n",
    "        else:       \n",
    "            color_with_alpha = color + (255,)\n",
    "        draw.rectangle([xmin, ymin, xmax, ymax], outline=color_with_alpha, width=2)\n",
    "\n",
    "    out = Image.alpha_composite(img_pil, new).convert(\"RGB\")\n",
    "    return T.ToTensor()(out) if return_pt else out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc4317b-42d2-4625-9468-4d09629ed67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(), # chcemy najpierw \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    # https://stackoverflow.com/questions/58151507/why-pytorch-officially-use-mean-0-485-0-456-0-406-and-std-0-229-0-224-0-2\n",
    "])\n",
    "\n",
    "dataset = MalariaPlasmodiumDataset(\n",
    "    \"/home/kamil/Downloads/plasmodium-phonecamera/train/\", images_transforms=images_transforms\n",
    ")\n",
    "\n",
    "#TODO: podzielmy sobie nasz dataset na 3 randomowe rozłączne subsety w proporcjach 0.85,0.15\n",
    "# torch.utils.data.random_split <= nasz przyjaciel \n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [0.85, 0.15]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af38b4ba-f84f-4985-96bc-57462ec06ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=1, \n",
    "    shuffle=True, num_workers=2,\n",
    "    collate_fn=lambda x: tuple(zip(*x))\n",
    ")\n",
    "\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(\n",
    "    val_set, batch_size=1, \n",
    "    shuffle=True, num_workers=2,\n",
    "    collate_fn=lambda x: tuple(zip(*x))\n",
    ")\n",
    "\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn_v2()\n",
    "\n",
    "num_classes = 2  # 1 zarodziec + tło\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "hidden_layer = 256\n",
    "model.roi_heads.mask_predictor = torchvision.models.detection.mask_rcnn.MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012b325c-8fa8-485d-8aa2-3c094e3ff5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# Parameters\n",
    "params = [p for p in model.parameters() if p.requires_grad] # only some parameters are trainable \n",
    "optimizer = torch.optim.Adam(params) # TWOJ_KOD_TUTAJ # TODO: create optimizer \n",
    "\n",
    "writer = SummaryWriter() \n",
    "\n",
    "\n",
    "# TODO: initialize best_eval_metric_result \n",
    "best_eval_metric_result = 0.0 #  TWOJ_KOD_TUTAJ \n",
    "\n",
    "num_epochs = 60\n",
    "for epoch in range(num_epochs):\n",
    "    # train \n",
    "    model.train() \n",
    "    for images, targets in tqdm(train_data_loader, desc=f\"Training epoch {epoch}\"):     \n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values()) / len(images)        \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # evaluation\n",
    "    model.eval()    \n",
    "    eval_metric = MeanAveragePrecision(iou_type=\"bbox\", iou_thresholds = [0.5])\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(val_data_loader, desc=\"Evaluation...\"):        \n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            output = model(images)\n",
    "    \n",
    "            # MAP metric \n",
    "            eval_metric.update(output, targets)    \n",
    "        # metryka po całej epoce \n",
    "        result = eval_metric.compute()            \n",
    "        writer.add_scalar(\"map@validation_set\", result['map'].detach().numpy(), epoch)\n",
    "        # Zapiszmy obecnie najlepszy model \n",
    "        if result['map'].detach().numpy() > best_eval_metric_result:           \n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            best_eval_metric_result  = result['map'].detach().numpy()\n",
    "            \n",
    "\n",
    "    # Po wyjściu z pętli walidacji powyżej zmienne targets i outputs nadal istnieją - skorzystamy z nich \n",
    "    # by wyświetlić jak wyglądają przykładowe detekcje po tej epoce \n",
    "    \n",
    "    bboxes_true = targets[0]['boxes']\n",
    "    bboxes_predicted = output[0]['boxes']\n",
    "    scores = output[0]['scores']\n",
    "    img_id = targets[0]['image_id']\n",
    "    img = val_set.dataset.get_single_plasmodium_path(targets[0]['image_id'])\n",
    "\n",
    "    # zapiszmy zdjecie z predykcjami obok prawdziwych zarodźców w tensorboard \n",
    "    writer.add_image(\n",
    "        f\"epoch {epoch}\", \n",
    "        torch.cat([\n",
    "            draw_bounding_boxes(img, bboxes_true, return_pt=True), \n",
    "            draw_bounding_boxes(img, bboxes_predicted, scores, color=(0,255,0), return_pt=True)\n",
    "            ], dim=2\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d080d6f8-6c3c-454e-859a-920bd973c70f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
