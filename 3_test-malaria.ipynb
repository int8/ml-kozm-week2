{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5f35a3-26a3-4e49-891b-2487fd6e39d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm \n",
    "\n",
    "def create_bbox_coords(bbox):\n",
    "    xmin = float(bbox.find('xmin').text)\n",
    "    ymin = float(bbox.find('ymin').text)\n",
    "    xmax = float(bbox.find('xmax').text)\n",
    "    ymax = float(bbox.find('ymax').text)\n",
    "    return [xmin, ymin, xmax, ymax]\n",
    "\n",
    "def create_mask(plasmodium_img, bbox):\n",
    "    xmin, ymin, xmax, ymax = create_bbox_coords(bbox)\n",
    "    mask = np.zeros((plasmodium_img.size[1], plasmodium_img.size[0]), dtype=np.uint8)\n",
    "    mask[int(ymin):int(ymax), int(xmin):int(xmax)] = 1 \n",
    "    return mask \n",
    "\n",
    "    \n",
    "class MalariaPlasmodiumDataset(torch.utils.data.Dataset):\n",
    "    # Będziemy czytać pliki jpg i odpowiadające im pliki XML \n",
    "    # z katalogu directory_root \n",
    "    # Podamy też transformacje jakie chcemy przeprowadzać na zwracanych wartościach \n",
    "    \n",
    "    def __init__(self, directory_root, images_transforms=None):\n",
    "\n",
    "        # Przypisujemy parametetry konstruktora do self \n",
    "        # Chcemy aby nasz przyszły obiekt wiedzial o tym gdzie szukać plików oraz \n",
    "        # jakie transformacje wykonywać na przeczytanych JPG \n",
    "        self.directory_root = directory_root        \n",
    "        self.images_transforms = images_transforms\n",
    "\n",
    "        # Listujemy wszystkie pliki które mają rozszerzenie \"JPG\" \n",
    "        all_image_files = sorted([img for img in os.listdir(directory_root) if img.endswith(\".jpg\")])\n",
    "        \n",
    "\n",
    "        # wśród zdjęć w naszym datasecie są takie, na których nie znaleziono zarodźca \n",
    "        # usuwamy je z datasetu - tzn zapisujemy do self.imgs_with_plasmodium tylko \n",
    "        self.imgs_with_plasmodium = []\n",
    "        for img_file in all_image_files:\n",
    "            xml_file = os.path.join(self.directory_root, img_file.replace(\".jpg\", \".xml\"))\n",
    "            tree = ET.parse(xml_file)\n",
    "            # wykrycie zarodźca na zdjęciu jpg jest równoważne z istnieniem taga \"object\" w XML - jeśli tylko znajdziemy takowy \n",
    "            # kwalifikujemy zdjęcie jako dobre do naszego wejściowego datasetu i dodajemy nazwę pliku do self.imgs_with_plasmodium  \n",
    "            if tree.findall('object'): \n",
    "                self.imgs_with_plasmodium.append(img_file)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        # \"magiczna\" metoda __getitem__ jest wykorzystywana kiedy chcemy aby nasz obiekt był dostępny poprzez operator [int] \n",
    "        # podobnie jak lista czy dict \n",
    "        single_plasmodium_img_path = self.get_single_plasmodium_path(idx)\n",
    "        single_annotation_file_path = single_plasmodium_img_path.replace(\".jpg\", \".xml\")\n",
    "        plasmodium_img = Image.open(single_plasmodium_img_path).convert(\"RGB\") \n",
    "        \n",
    "        # read xml file\n",
    "        annotations = ET.parse(single_annotation_file_path)\n",
    "        boxes = []\n",
    "        masks = []        \n",
    "        \n",
    "        for detected_plasmodium in annotations.findall('object'):            \n",
    "            bbox = detected_plasmodium.find('bndbox')\n",
    "            boxes.append(\n",
    "                create_bbox_coords(bbox)\n",
    "            )\n",
    "        \n",
    "            masks.append(\n",
    "                create_mask(\n",
    "                    plasmodium_img, bbox\n",
    "                )\n",
    "            )\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        masks = torch.as_tensor(np.array(masks), dtype=torch.uint8)  \n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        labels = torch.ones((len(boxes),), dtype=torch.int64)                            \n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])            \n",
    "        iscrowd = torch.zeros((len(boxes),), dtype=torch.int64)\n",
    "\n",
    "        \n",
    "        if self.images_transforms is not None:\n",
    "            transformed_plasmodium_img = self.images_transforms(plasmodium_img)\n",
    "        else:\n",
    "            transformed_plasmodium_img = plasmodium_img            \n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        target[\"masks\"] = masks\n",
    "        \n",
    "        return transformed_plasmodium_img, target\n",
    "\n",
    "    def get_single_plasmodium_path(self, idx):\n",
    "        single_plasmodium_img_path = os.path.join(self.directory_root, self.imgs_with_plasmodium[idx])\n",
    "        return single_plasmodium_img_path\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        # magiczna metoda __len__ jest używana gdy na instancji wykonujemy len() \n",
    "        return len(self.imgs_with_plasmodium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d574f786-5568-49e1-ad84-a09d1221930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def draw_bounding_boxes(image_path, bboxes, scores=None, color=(255, 0, 0), return_pt = False):    \n",
    "    img_pil = Image.open(image_path).convert(\"RGBA\")\n",
    "    new = Image.new('RGBA', img_pil.size, (255, 255, 255, 0))\n",
    "    draw =ImageDraw.Draw(new)\n",
    "\n",
    "    for i, box in enumerate(bboxes):\n",
    "        xmin, ymin, xmax, ymax = box        \n",
    "        if scores is not None:          \n",
    "            alpha = int(255 * scores[i])  # Convert score to an alpha value.                      \n",
    "            color_with_alpha = color + (alpha,)\n",
    "        else:       \n",
    "            color_with_alpha = color + (255,)\n",
    "        draw.rectangle([xmin, ymin, xmax, ymax], outline=color_with_alpha, width=2)\n",
    "\n",
    "    out = Image.alpha_composite(img_pil, new).convert(\"RGB\")\n",
    "    return T.ToTensor()(out) if return_pt else out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4de2f6-aae7-43c3-85d8-f6e6448f771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn_v2()\n",
    "num_classes = 2  # 1 zarodziec + tło\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "hidden_layer = 256\n",
    "model.roi_heads.mask_predictor = torchvision.models.detection.mask_rcnn.MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939eb25e-8f35-4cb9-bbde-b9deacdf487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"best_model.pth\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308a00ed-d034-4c85-9ec1-209afdb3a6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(), # chcemy najpierw \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    # https://stackoverflow.com/questions/58151507/why-pytorch-officially-use-mean-0-485-0-456-0-406-and-std-0-229-0-224-0-2\n",
    "])\n",
    "\n",
    "dataset = MalariaPlasmodiumDataset(\n",
    "    \"../plasmodium-phonecamera/test/\", images_transforms=images_transforms\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=1, \n",
    "    num_workers=1,\n",
    "    collate_fn=lambda x: tuple(zip(*x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bcf501-5d71-4af5-89c8-8811ed02bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "test_metric = MeanAveragePrecision(iou_type=\"bbox\", iou_thresholds = [0.5])\n",
    "with torch.no_grad():\n",
    "    for images, targets in tqdm(test_data_loader):                \n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        output = model(images)    \n",
    "        test_metric.update(output, targets)    \n",
    "        torch.cuda.empty_cache()\n",
    "print(test_metric.compute()['map'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cfdc89-6b81-4025-ae33-7c9a2c61ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "with torch.no_grad():    \n",
    "    image, target = random.choice(dataset)\n",
    "    target = {k: v.to(device) for k, v in target.items()}\n",
    "    output = model([image.to(device)])\n",
    "    output[0]['scores'][output[0]['scores'] < 0.9] = 0\n",
    "    test_metric.update(output, [target])    \n",
    "    torch.cuda.empty_cache()    \n",
    "    bboxes_true = target['boxes']\n",
    "    bboxes_predicted = output[0]['boxes']\n",
    "    scores = output[0]['scores']\n",
    "    img_id = target['image_id']\n",
    "    img = dataset.get_single_plasmodium_path(target['image_id'])\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
