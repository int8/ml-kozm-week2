{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78f26d71-b246-411a-9305-73f835eb7ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import numpy as np\n",
    "TWOJ_KOD = None \n",
    "# TODO: Zaprojektuj sieć neuronową która konsumuje wektory o długości 1024 (embeddingi) i zwraca binarną odpowiedź (sigmoid) \n",
    "# Pośrednie warstwy niech mają kolejno 150 i 15 neuronów a funkcjami aktywacji niech będzie nn.ReLU \n",
    "class ReviewClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(1024, 150),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(150,15),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(15, 1),\n",
    "            nn.Sigmoid()\n",
    "        ) \n",
    "        \n",
    "    \n",
    "    def forward(self, x):        \n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1a43a10-7b58-4e69-a20c-4e0f91442279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "#TODO: wczytaj zapisane dane z embeddingami\n",
    "df = pd.read_feather(\"amazon_with_embeddings.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7e2b30d-a8d1-4825-abc9-852aa044b844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'title', 'content', 'embeddings'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf669d2-2b63-4479-b91b-b9dae3178b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04330444, -0.00665665,  0.01806641, ..., -0.04470825,\n",
       "       -0.02055359,  0.01741028])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "202c52e6-7f2b-4fec-adff-9c43373e8f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150c30ff-3d6f-4f3a-b871-cb9680f2c98b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccff75c1-29ad-44f8-9c22-20c8fc113978",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1.0)\n",
    "# TODO: Podziel dane na train, val, test (25k, 5k, reszta) \n",
    "train_df = df[:25000]\n",
    "val_df = df[25000:30000]\n",
    "test_df = df[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57a37fcc-312e-444c-bf9a-886f0cde45db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a983fb478843008d90928c04ff6836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15069cdf814042ceabb686110bc64107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "evaluating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchmetrics import Accuracy\n",
    "from tqdm.notebook import tqdm \n",
    "import numpy as np \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "model = ReviewClassifier()\n",
    "bce_loss = torch.nn.BCELoss()  # TODO: https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html\n",
    "\n",
    "batch_size = 128\n",
    "adam_optimizer = torch.optim.Adam(model.parameters()) #TODO: https://pytorch.org/docs/stable/generated/torch.optim.Adam.html [use lr=0.0005]\n",
    "nr_of_epochs = 1\n",
    "losses = []\n",
    "for epoch in tqdm(range(nr_of_epochs)):\n",
    "    # shuffle \n",
    "    train_df = train_df.sample(frac=1.0)\n",
    "    current_index = 0 \n",
    "    while current_index < len(train_df):        \n",
    "        batch_x = np.array(\n",
    "            train_df.embeddings[current_index:(current_index + batch_size)].tolist()\n",
    "        )\n",
    "        batch_y = np.array(\n",
    "            train_df.label[current_index: (current_index + batch_size)].tolist()\n",
    "        )\n",
    "        \n",
    "        tensor_batch_x = torch.Tensor(batch_x)\n",
    "        tensor_batch_y = torch.Tensor(batch_y).reshape(-1, 1)\n",
    "        \n",
    "        pred = model.forward(tensor_batch_x)\n",
    "        loss = bce_loss(pred, tensor_batch_y)\n",
    " \n",
    "        # Backpropagation\n",
    "        loss.backward() # Liczenie gradientu wag modelu\n",
    "        adam_optimizer.step() # adam oblicza nowe parametry sieci \n",
    "        adam_optimizer.zero_grad()\n",
    "        \n",
    "        current_index += batch_size\n",
    "        losses.append(float(loss.detach().numpy()))\n",
    "        \n",
    "    model.eval()\n",
    "    metric = Accuracy(task='BINARY')\n",
    "    for _, eval_row in tqdm(val_df.iterrows(), desc='evaluating'):\n",
    "        pred = model.forward(\n",
    "            torch.Tensor(np.array(eval_row.embeddings))\n",
    "        )\n",
    "        metric.update(pred, torch.Tensor([eval_row.label]))\n",
    "    metric_value = metric.compute()\n",
    "    writer.add_scalar('Accuracy/eval', metric_value, epoch)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbca90af-e8fd-4dbb-9daa-043ccf000da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "338cd70f-9e57-4e6d-8057-06ee40f1d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.reset_index().to_feather(\"test_df.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73f910c-3836-4826-a09a-1b40d6b6cfc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
